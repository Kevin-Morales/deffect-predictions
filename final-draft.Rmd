---
title: "Predictive Models for Software Deffects Using Supervised Learning"
author: "Kevin Morales"
date: "`r Sys.Date()`"
---


```{r setup, include=FALSE, cache = TRUE}
knitr::opts_chunk$set(cache=TRUE, fig.height = 7, fig.width = 7)
library(e1071)
library(keras)
library(pROC)
library(rsample)
library(tidyverse)
library(xgboost)

isBuggy <- function (bug) {
return(ifelse(bug > 0, 1, 0))
}

unified_class <- as_tibble(read_csv("Unified-class.csv"))
unified_class$has_bugs <- as.numeric(lapply(unified_class$bug, isBuggy))

bugs_per_nl <- unified_class %>%
select(bug, NL)

bugs_per_nlm <- unified_class %>%
select(bug, NLM) 



bugs_per_lldc <- unified_class %>%
select(bug, LLDC)

bugs_per_ldc <- unified_class %>%
select(bug, LDC)

bugs_per_nlg <- unified_class %>%
select(bug, NLG)

bugs_per_nle <- unified_class %>%
select(bug, NLE)


bugs_per_tnos <- unified_class %>%
select(bug, TNOS)


bugs_per_tlloc <- unified_class %>%
select(bug, TLLOC)


# Sample / split the data.
x_split <- initial_split(unified_class, prop = 0.7, strata = has_bugs)
x_train <- training(x_split)
x_test <- testing(x_split)
y_train <- x_train$has_bugs
y_test <- x_test$has_bugs
```

# Introduction{-}

(*NOTE*: The accompanying source code can be found inside the following repository web address: [Software Deffect Predictions Source](https://github.com/Kevin-Morales/deffect-predictions) )

The software development industry is lately being guided by innovative capabilities possible due to predictive modeling and machine learning.
Integrated development environments are no exception. Microsoft, for example, can offer users a better auto completion experience by training a machine learning model using Git Hub repositories as its data set.
(See the following documentation page: [Visual Studio IntelliCode](https://visualstudio.microsoft.com/services/intellicode/))
However, research is also being conducted concerning the prediction of software deffects.
The idea entails finding a relevant data set (i.e., computing source code metrics, type checking, ETC.), finding features that directly correlate to the number of deffects, and feeding them to a certain predictive or machine learning object model.
This is not as simple as it might seem.


Software developers like us are notorious for shipping software deffects with every release of our production code. We may utilize the appropriate design patterns; we may utilize principles such as test-driven development, and we may even integrate rule sets and linting tools to check for certain aspects of code quality. Yet, we are still delivering deffective software to customers. This is because the craft of software development is uncertain and unpredictable, and humankind is fallible.
Nevertheless, it is necessary to investigate whether computers can do better at finding deffects through predictive modeling and machine learning, since there are legacy code bases to maintain, and we are still far from software that can write new systems or applications.
The goal is to build a classifier that can tell us whether a code fragment is deffective or not.
The task of building such a classifier will be carried out as follows:

* First, research that has already been done will be presented;
* a data set will be described and analyzed for features appropriate for deffect prediction;
* the investigation will end after applying extreme gradient boosting, logistic regression, neural networks, and support vector machines to build various classifiers to compare.

# Current Research{-}

A conference took place in 2018, where papers were presented regarding predictive models for software analytics.
(See the following page for details: ["A Public Unified Bug Dataset for Java"](https://dl.acm.org/doi/10.1145/3273934.3273936))
This paper from authors who are affiliated with the university of Szeged, Hungary, presents a dataset compiled to aid in the creation of predictive models for software deffects (also known as software bugs). They utilized five datasets that were already available, according to their own research. Furthermore, they downloaded the source code for the datasets they found. They used decision tree algorithms to predict whether a certain Java class was deffective.
The following link shows the archive for the dataset downloads: [Download Unified Bug Dataset](http://www.inf.u-szeged.hu/~ferenc/papers/UnifiedBugDataSet/)
(Although the paper for this data repository was presented in 2018, the latest version was published in December of 2019, and it is the latest version that was used to build the classifiers.)

Before continuing with the description and important statistics of the dataset, it is worth mentioning that it does not take into consideration factors such as static versus dynamic typing.
(For such research, see (these papers by Dr. Andreas Stefik and others)[https://web.cs.unlv.edu/stefika/research.html]; in particular, see papers 23 and 27 on the list.)
Nor does it take into account evidence for programming language constructs and their readability (see above link).
Instead, the dataset has eight particular features that promise innovation in refactoring tools, screen reader sonification when pared with an integrated development environment, and perhaps project management software.

# Feature Description

As mentioned previously, there are eight particular features that helped the models that were trained. A table of the statistical summary of each feature will be shown, along with a brief description of the feature, and a plot showing the correlation with the number of bugs recorded for each data point.
Note that deffects at the class level were explored; analysis and modeling has yet to be done at the file level.

## Nesting Levels (NL){-}

```{r echo = FALSE, warning = FALSE}
ggplot(bugs_per_nl, aes(bug, NL, group = 1))+
geom_boxplot()+
labs(title = "Summary of Software Deffects Versus Nesting Levels")
knitr::kable(summary(bugs_per_nl), caption = "Summary of statistics for the number of nesting levels in a Java class.")
```

The nesting levels of a code fragment refers to how many block-structured elements are inside one another.
The following pseudocode shows what is meant by this:

~~~
for (int i = 0; i < 100; i++) {
int j = 0;
while (j < 99) {
if (i%2 == 0) {
System.out.println("Number is even.");
}
j++;
}
i++;
}
~~~

In this case, there are three levels of nesting: the outermost loop, a while loop at level two, and a conditional at level three.
In a real-world scenario, code that is written in that manner is likely to contain deffects. Furthermore, such code fragments can be found deep in systems that have millions of lines of code.


```{r echo = FALSE, message = FALSE, warning = FALSE}
ggplot(bugs_per_nl, aes(bug, NL))+
geom_point()+
geom_text(aes(label = NL), hjust = 0, vjust = 0)+
geom_smooth(se = FALSE)+
labs(
x = "Number of Deffects per Java Code Element",
y = "Levels of Nesting in Java Code Element",
title = "Software Deffects Increase as Nesting Levels Increase",
caption = "Data retrieved from the Unified Bug Dataset")
```

## Number of Local Methods (NLM){-}

```{r echo = FALSE, message = FALSE, warning = FALSE}
ggplot(bugs_per_nlm, aes(bug, NLM, group = 1))+
geom_boxplot()+
labs(title = "Summary of Software Deffects Versus Local Methods")
knitr::kable(summary(bugs_per_nlm), caption = "Summary statistics for the number of methods within a Java class.")
```

Local class methods refer to those that are not inherited from other classes. The more methods found within a class, the more that class will be likely to contain deffects. (Not to mention that if the class contains many methods, it is time for a developer to question the design of such class, and perhaps refactor it into smaller, more managable classes.)

```{r echo = FALSE, mwssage = FALSE, warning = FALSE}
ggplot(bugs_per_nlm, aes(bug, NLM))+
geom_point()+
geom_text(aes(label = NLM), hjust = 0, vjust = 0)+
geom_smooth(se = FALSE)+
labs(
x = "Number of Deffects",
y = "Number of Local Methods",
title = "Software Deffects Increase as Number of Methods Increase",
caption = "Data retrieved from the Unified Bug Dataset")
```

## Logical Lines of Duplicated Code (LLDC){-}

```{r echo = FALSE, message = FALSE, warning = FALSE}
ggplot(bugs_per_lldc, aes(bug, LLDC, group = 1))+
geom_boxplot()+
labs(title = "Summary of Software Deffects Versus Logical Lines of Duplicated Code")
knitr::kable(summary(bugs_per_lldc), caption = "Summary statistics for the number of logical lines of code.")
```

Logical code fragments are those that do not contain comment lines or empty ones. It is a best practice to avoid duplication wherever possible. It is easy to create bugs using duplicated code, thus principles such as inheritance have been added to languages such as Java. (In fact, any signs of code duplication should make software developers question the current design of such code fragments, or the components in which they are found.) It therefore makes sense that this feature correlates with the number of bugs.

```{r echo = FALSE, message = FALSE, warning = FALSE}
ggplot(bugs_per_lldc, aes(bug, LLDC))+
geom_point()+
geom_text(aes(label = LLDC), hjust = 0, vjust = 0)+
geom_smooth(se = FALSE)+
labs(
x = "Number of Deffects per Java Code Element",
y = "Logical Lines of Code",
title = "Software Deffects Increase Due to Code Duplication",
caption = "Data retrieved from the Unified Bug Dataset")
```

It is important to take a moment to notice that correlation does not necessarily mean causation. Duplicated code may mean importing the `java.util.concurrent` package all throughout a certain system. However, code that is duplicated and has deffects is code that contains conditionals, or method calls that require small changes in parameters.

## Lines of Duplicated Code (LDC){-}

```{r echo = FALSE, message = FALSE, warning = FALSE}
ggplot(bugs_per_ldc, aes(bug, LDC, group = 1))+
geom_boxplot()+
labs(title = "Summary of Software Deffects Versus Lines of Duplicated Code")
knitr::kable(summary(bugs_per_ldc), caption = "Summary statistics for the number of duplicated lines of code (including comments).")
```

These include comments and other parts of a physical Java source file, such as API documentation, empty lines for readability, indenting, ETC.

```{r echo = FALSE, message = FALSE, warning = FALSE}
ggplot(bugs_per_ldc, aes(bug, LDC))+
geom_point()+
geom_text(aes(label = LDC), hjust = 0, vjust = 0)+
geom_smooth(se = FALSE)+
labs(
x = "Number of Deffects per Java Code Element",
y = "Lines of Duplicated Code",
title = "Software Deffects Increase as More Code is Duplicated",
caption = "Data retrieved from the Unified Bug Dataset")
```

## Number of Local Getters (NLG){-}


```{r echo = FALSE, message = FALSE, warning = FALSE}
ggplot(bugs_per_nlg, aes(bug, NLG, group = 1))+
geom_boxplot()+
labs(title = "Summary of Software Deffects Versus Local Getters")
knitr::kable(summary(bugs_per_nlg), caption = "Summary statistics for property getters not inherited from other classes.")
```

This is the same scenario as that of the number of local methods. Objects that are not thread-safe, along with setter methods, can contribute to software deffects.

```{r echo = FALSE, message = FALSE, warning = FALSE}
ggplot(bugs_per_nlg, aes(bug, NLG))+
geom_point()+
geom_text(aes(label = NLG), hjust = 0, vjust = 0)+
geom_smooth(se = FALSE)+
labs(
x = "Number of Deffects per Java Code Element",
y = "Number of Getters Per Class",
title = "Software Deffects Increase as Getter Methods Increase",
caption = "Data retrieved from the Unified Bug Dataset")
```

## Number of Nesting Levels Including Else-if Constructs (NLE){-}

```{r echo = FALSE, message = FALSE, warning = FALSE}
ggplot(bugs_per_nle, aes(bug, NLE, group = 1))+
geom_boxplot()+
labs(title = "Summary of Software Deffects Versus Nesting Level Else-if")
knitr::kable(summary(bugs_per_nle), caption = "Summary statistics of the number of nesting levels (including else-if statements) within a Java class.")
```

It is the same scenario as the first feature.
Unfortunately, code containing nested blocks is sometimes found in domains such as system software (e.g., the lexical analyzer of the C-Sharp compiler). Nesting code is often preferred over refactoring such fragments into more manageable function or method.

```{r echo = FALSE, message = FALSE, warning = FALSE}
ggplot(bugs_per_nle, aes(bug, NLE))+
geom_point()+
geom_text(aes(label = NLE), hjust = 0, vjust = 0)+
geom_smooth(se = FALSE)+
labs(
x = "Number of Deffects per Java Code Element",
y = "Nesting Level Else-if",
title = "Software Deffects Increase as Nesting Levels Increase",
caption = "Data retrieved from the Unified Bug Dataset")
```

##  Total Number of Statements (TNOS){-}

```{r echo = FALSE, message = FALSE, warning = FALSE}
ggplot(bugs_per_tnos, aes(bug, TNOS, group = 1))+
geom_boxplot()+
labs(title = "Summary of Software Deffects Versus Number of Statements")
knitr::kable(summary(bugs_per_tnos), caption = "Summary statistics for the total number of statements found in a Java class.")
```

Experience shows that the more complex a function or method becomes, the more difficult it is to maintain and the more error prone it becomes.

```{r echo = FALSE, message = FALSE, warning = FALSE}
ggplot(bugs_per_tnos, aes(bug, TNOS))+
geom_point()+
geom_text(aes(label = TNOS), hjust = 0, vjust = 0)+
geom_smooth(se = FALSE)+
labs(
x = "Number of Deffects per Java Code Element",
y = "Number of Statements",
title = "Software Deffects Increase Due to Longer Methods",
caption = "Data retrieved from the Unified Bug Dataset")
```

## Total Number of Logical Lines of Code (TLLOC){-}

```{r echo = FALSE, message = FALSE, warning = FALSE}
ggplot(bugs_per_tlloc, aes(bug, TLLOC, group = 1))+
geom_boxplot()+
labs(title = "Summary of Software Deffects Versus Total Logical Lines of Code")
knitr::kable(summary(bugs_per_tnos), caption = "Summary statistics for the total number of logical lines found in a Java class.")
```

This feature records how many executable lines of code a particular Java class contains.

```{r echo = FALSE, message = FALSE, warning = FALSE}
ggplot(bugs_per_tlloc, aes(bug, TLLOC))+
geom_point()+
geom_text(aes(label = TLLOC), hjust = 0, vjust = 0)+
geom_smooth(se = FALSE)+
labs(
x = "Number of Deffects per Java Code Element",
y = "TotalLogical Lines of Code",
title = "Software Deffects Increase Due to Longer Methods",
caption = "Data retrieved from the Unified Bug Dataset")
```

# The Modeling Phase{-}

```{R include = FALSE, cache = TRUE}
set.seed(123)
model_glm <- glm(y_train~NL+NLM+LLDC+LDC+NLG+NLE+TNOS+TLLOC, data = x_train, family = "binomial")
predictions_glm <- predict(model_glm, x_test, type = "response")
acc_glm <- mean(round(predictions_glm) == y_test)
auc_glm = auc(y_test, predictions_glm)

data_train <- select(x_train, NL, NLM, LLDC, LDC, NLG, NLE, TNOS, TLLOC)
data_test <- select(x_test, NL, NLM, LLDC, LDC, NLG, NLE, TNOS, TLLOC)
train_m <- as.matrix(data_train)
test_m <- as.matrix(data_test)


set.seed(123)
model_svm <- svm(train_m, y_train)
predictions_svm <- predict(model_svm, test_m)
acc_svm <- mean(round(predictions_svm) == y_test)
auc_svm = auc(y_test, predictions_svm)

set.seed(123)
model_xgb <- xgboost(data = train_m, label = y_train, max_depth = 8, eta= 0.3, nrounds = 4, objective = "binary:logistic")

predictions_xgb <- predict(model_xgb, test_m)
acc_xgb <- mean(round(predictions_xgb) == y_test)
auc_xgb = auc(y_test, predictions_xgb)


# one hot encoding labels is what keras requires
trainLabels = to_categorical(y_train)
testLabels = to_categorical(y_test)

# Get the number of units and the input shape for the model.
x_units <- 2*nrow(train_m)
x_shape <- ncol(train_m)

# create neural network
model = keras_model_sequential()
model %>% 
  layer_dense(units=x_units,
              activation='sigmoid',
              input_shape=c(x_shape))  %>%
  layer_dense(units=2,
              activation='sigmoid')

# compile model
model %>%
  compile(loss='binary_crossentropy',
          optimizer='adam',
          metrics='accuracy')

# train model
history = model %>%
  fit(train_m,
      trainLabels,
      epoch = 10,
      batch_size=1)

# make predictions
predictions_nn <- model %>%
predict_proba(test_m)

acc_nn <- mean(round(predictions_nn[, 2]) == y_test)
auc_nn = auc(y_test, predictions_nn[, 2])


model_data <- data.frame(Model_name = c("Logistic Regression", "Support Vector Machine", "Extreme Gradient Boosting", "Keras Neural Network"),
model_acc = as.numeric(c(acc_glm, acc_svm, acc_xgb, acc_nn)),
model_auc = c(auc_glm, auc_svm, auc_xgb, auc_nn))


```

The Unified Bug Dataset repository containes `r nrow(unified_class)` observations of Java classes found in five different projects such as the Eclipse family of open source integrated development environments. To train the chosen models, the data was split into $0.7%$ training, and the rest was used for the predictions phase.
A column was added to the Unified Class portion of the data, which would tell the models which data point was recorded as deffective. It is a binary column that had a 0 when the number of deffects was 0, and 1 otherwise.

In general, it was found that the conclusions made by the authors of the Unified Bug Dataset agreed with the recorded results, namely that tree-based models are best suited for predicting whether a software class (a Java class, that is) is deffective or not.
The accuracy and the area under the curve were obtained for the chosen models.
For the extreme gradient boosting model, it was found that a slower learning rate of $0.3$ was optimal, along with a maximum depth of 8 levels, and an iteration number of 4. Because a neural network with 100 or even 25 epochs takes a long amount of time to train, the number was reduced to 10, since during analysis, the model reported the same accuracy when trained for 25 epochs. Furthermore, the loss function that was used for the neural network is called binary crossentropy. (The function categorical crossentropy would cause the prediction function for the neural network to output 0 or 1, rather than the probabilities.)
During analysis, the accuracy and area under the curve were being calculated incorrectly. The issue was resolved by ensuring that every model predicted probabilities rather than class values (useful for the area under the curbe), and that those probabilities were rounded when needed (useful for calculating the accuracy).
The results are now shown below:

```{r echo = FALSE}
knitr::kable(model_data, col.names=c("Model Name", "Accuracy", "Area Under the Curve"), caption = "Results after training 4 types of models.")
```

# Variable Importance for the Best Model

As one can see from the table above, Extreme Gradient Boost performed the task of classifying Java classes with deffects better than the other models. Now, the question becomes: What features contributed to the performance of the model?
According to the [documentation for X G Boost](http://127.0.0.1:15819/library/xgboost/html/xgb.importance.html), the `Gain` metric is interpreted as the percentage contributed to the model (the higher the percentage, the higher the importance of a certain feature.). The feature importance results are shown below:

```{r echo = FALSE, cache = TRUE}
# Calcculate the variable importance for XG Boost, as that is the best model.
important_df_xgb <- data.frame(xgb.importance(model = model_xgb))

knitr::kable(important_df_xgb, caption = "Ranking of features (by Gain metric) according to the extreme gradient boosting model.")
```

# A Note About Other Features From the Data{-}

There were aspects of each Java class that could have been useful for the training of the models. Such variables had to do with decoupling metrics and such. Indeed one knows that lack of decoupling leads to systems that under perform or that are deffective. However, the correlation did not show up during analysis. Never the less, the features used to train the models result in some possible implications for refactoring tools included in integrated development environments.

# Future Research and Conclusions{-}

Although the dataset contained classes written in Java, this can be extended to languages such as Rust, Go, C++, and others. When that occurrs, refactoring tools can generate warnings regarding the nesting levels of a function, the number of statements in a particular class, reduction of object mutability by removing setter methods (indirect usage of the number of getters feature). Taking into account the many advances in modern development environments and web technologies, this feedback can easily be provided almost immediately.

